@import Main._
@import readme.Sample._
@import ammonite.ops._
@val ammoniteTests = 'amm/'src/'test/'scala/'ammonite/'session
@val replSource = 'amm/'src/'main/'scala/'ammonite
@val advancedTests = ammoniteTests/"AdvancedTests.scala"
@sect("Scala Scripts", "Lightweight Programming in Scala")
  @p
    @b{Scala scripts} are lightweight files containing Scala code that
    can be directly run from the command line. Unlike normal Scala projects,
    Scala scripts let you save and run code without setting up a "build-file"
    or "project". Scala Scripts are useful as something in between the REPL and
    a full-fledged Scala/SBT project: more permanent than a REPL session, but
    more lightweight and easier to set up than a SBT project.
  @p
    Creating an Ammonite Script is just a matter of creating a
    @hl.scala{MyScript.sc} with some Scala code in it, and running it from
    within the Ammonite REPL or @sect.ref{From Bash}. Writing Scala code
    doesn't get much easier than that! For example, Ammonite's own
    @lnk("Continuous Integration Scripts", "https://github.com/lihaoyi/Ammonite/tree/master/ci")
    are written as @code{.sc} Scala Scripts, as are @lnk("Haoyi's blog",
    "https://github.com/lihaoyi/blog") and @lnk("resume",
    "https://github.com/lihaoyi/Resume"). These are all examples of using
    Scala Scripts to do some simple (or not so simple!) tasks in just a few
    files, without the hassle of setting up a heavyweight SBT project.

  @p
    To begin with, download the Ammonite script-runner:

  @hl.sh
    @replCurl

  @p
    And read on to learn about how Scala scripts work.

  @sect{Script Files}
    @p
      Ammonite defines a format that allows you to load external scripts into
      the REPL; this can be used to save common functionality so it can be
      used at a later date. In the simplest case, a script file is simply a
      sequence of Scala statements, e.g.
  
    @hl.scala
      // MyScript.sc
      // print banner
      println("Welcome to the XYZ custom REPL!!")

      // common imports
      import sys.process._
      import collection.mutable

      // common initialization code
      val x = 123
      ...
    @p
      You can write any Scala code you want in an Ammonite script, including
      top-level statements and definitions (e.g. the @code{println} and
      @hl.scala{val x = 123} above) that are not valid in "normal" Scala
      projects. You do not need to wrap these sorts of top-level statements
      or expressions in boilerplate @hl.scala("object Foo{...}") wrappers:
      this is all done automatically for you by Ammonite.

    @p
      After that, it's a matter of running the script
      @sect.ref{From the REPL} or @sect.ref{From Bash}
  
    @sect{Script Imports}
      @p
        No code stands alone; scripts depend on other scripts. Often they depend
        on third party libraries, as there's so much code out there already
        written it doesn't make sense to re-invent everything yourself.

      @p
        Ammonite Scripts allow you to import @sect.ref{Other Scripts}, just like
        any Bash or Python scripts do. Furthermore, they let you cleanly depend
        on third party libraries: since Ammonite runs on the @lnk("JVM",
        "https://en.wikipedia.org/wiki/Java_virtual_machine"), this means
        @sect.ref{Ivy Dependencies}. Ammonite will ensure that the relevant
        dependencies are always downloaded and used, and you never need to worry
        about remembering to "install" things before running your scripts!

      @sect{Other Scripts}
        @p
          Like other scripting languages, Ammonite Scripts allow you to break your
          script into multiple files, and import them from each other in order to
          use what is in each file. Unlike "Normal" Scala projects, there is no
          need to set up a @code{src/main/scala} folder, and create a build file,
          and all these other things: simply split your script into two files, and
          import one from the other using @sect.ref{import $file}:
    
        @hl.ref('amm/'src/'test/'resources/'importHooks/"Basic.sc")
    
        @hl.ref('amm/'src/'test/'resources/'importHooks/"FileImport.sc")
    
        @p
          Here, we are defining a simple @hl.scala{val} in @code{Basic.scala}, and
          then importing it from @code{FileImport.scala}. And of course, we can
          use what we defined in @code{FileImport.scala} and import it in another
          file
    
        @hl.ref('amm/'src/'test/'resources/'importHooks/"IndirectFileImport.sc")
    
        @p
          And so on, importing files as many or as deep as you want.
    
        @p
          @hl.scala{$file} imports inside Scala Scripts behave the same as
          @hl.scala{$file} imports @sect.ref("import $file",
          "within the Ammonite-REPL"), and have the same characteristics:

        @ul
          @li
            @sect.ref{Imported Scripts are Re-used}
          @li
            @sect.ref{Cannot directly import from inside a Script}
          @li
            @sect.ref{Renamed-scripts and multiple-scripts}


      @sect{Ivy Dependencies}
        @p
          You can easily make use of external Ivy artifacts right in your
          scripts, without needing to set up a separate build file. Simply use a
          @sect.ref{import $ivy}, just as you would in the
          @sect.ref{Ammonite-REPL}, and it will be available in the script for you
          to use, e.g. here we make use of the @lnk("Scalatags",
          "http://www.lihaoyi.com/scalatags/") library:

        @hl.ref('amm/'src/'test/'resources/'importHooks/"IvyImport.sc")

    @sect{Multi-stage Scripts}
      @p
        By default, everything in a script is compiled and executed as a single
        block. While you can use @sect.ref{Magic Imports} to load other scripts
        or Ivy artifacts before your script runs, those can only load "hardcoded"
        scripts or artifacts, and cannot e.g. load different scripts depending on
        some runtime variables.

      @p
        If you want to load different scripts or ivy artifacts depending on
        runtime values, you can use the runtime-equivalent of magic imports:

      @ul
        @li
          @hl.scala{import $cp} becomes @hl.scala{load.cp}
        @li
          @hl.scala{import $file} becomes @hl.scala{load.module}
        @li
          @hl.scala{import $ivy} becomes @hl.scala{load.ivy}

      @p
        These are plain-old-Scala-functions that let you pass in a
        @hl.scala{Path} to a script to load, or load different Ivy artifacts
        depending on runtime values. However, since these functions get run
        *after* the current compilation block is compiled, you need to split
        your script into two compilation blocks, and can only use the results
        of the @hl.scala{load}ed code in subsequent blocks:
    
      @hl.scala
        // print banner
        println("Welcome to the XYZ custom REPL!!")
        val scalazVersion = "7.1.1"
        load.ivy("org.scalaz" %% "scalaz-core" % scalazVersion)
    
        @@
    
        // common imports
        import scalaz._
        import Scalaz._
    
        // use Scalaz!
        ...

      @p
        In general, this should not be necessary very often: usually you should
        be able to load what you want using @sect.ref{Magic Imports}.
        Nevertheless, sometimes you may find yourself needing to get "under the
        hood" and use these @hl.scala{load}ing functions directly. When that
        happens, using @sect.ref{Multi-stage Scripts} is the way to go.
    
    @sect{Script Arguments}
      @p
        Often when calling a script from the external command-line (e.g.
        Bash), you need to pass arguments to configure its behavior. With
        Ammonite, this is done by defining a @hl.scala("@main") method, e.g.

      @hl.ref(wd/'integration/'src/'test/'resources/'ammonite/'integration/'basic/"Args.sc")

      @p
        When the script is run from the command line:

      @hl.sh
        amm Args.sc 3 Moo

      @p
        The top-level definitions execute first (e.g. setting @hl.scala{x}),
        and then the @hl.scala("@main") method is called with the arguments you
        passed in. You can also pass in named arguments using `--` to demarcate
        them:

      @hl.sh
        amm Args.sc -- --i 3 --s Moo

      @p
        Default arguments behave as you would expect (i.e. they allow you to
        omit it when calling) and arguments are parsed using the
        @hl.scala{scopt.Read} typeclass, which provides parsers for primitives
        like @code{Int}, @code{Double}, @code{String}, as well as basic
        data-structures like @code{Seq}s (taken as a comma-separated list) and
        common types like @sect.ref{Paths}.
      @p
        If you pass in the wrong number of arguments, or if an argument fails
        to deserialize, the script will fail with an exception.

      @p
        The @hl.scala{main} method does not get automatically called when you
        @hl.scala{load.module} or @hl.scala{load.exec} a script from @i{within}
        the Ammonite REPL. It gets imported into scope like any other method or
        value defined in the script, and you can just call it normally.

    @sect{Multiple Main Methods}
      @p
        If you have only a single @hl.scala("@main") method, any arguments that
        you pass to the script get used as arguments to that @hl.scala("@main").
        But if you have @i{multiple} @hl.scala("@main") methods, the first
        argument to the script is used to select which @hl.scala("@main") method
        to call. e.g. given:

      @hl.ref(
        wd/'integration/'src/'test/'resources/'ammonite/'integration/'basic/"MultiMain.sc",
        className = "scala"
      )

      @p
        You can call it via

      @hl.sh
        amm MultiMain.sc mainA

      @p
        Or

      @hl.sh
        amm MultiMain.sc functionB 2 "Hello"

    @sect{Bundled Libraries}
      @p
        While Ammonite allows you to load any Java or Scala library for use
        via the @sect.ref("import $ivy", "http://www.lihaoyi.com/Ammonite/#IvyDependencies")
        syntax, it also comes bundled with some basic libraries, e.g.
        @lnk("Scalaj-HTTP", "https://github.com/scalaj/scalaj-http") for making
        HTTP calls, or the @lnk("uPickle", "http://www.lihaoyi.com/upickle-pprint/upickle/")
        library with it's @lnk("JSON Api", "http://www.lihaoyi.com/upickle-pprint/upickle/#JSONAPI")
        for dealing with the common JSON format.

      @p
        For example, here's a tiny script that offers two main methods, one
        to shorten a github link using Scalaj-HTTP and the @code{git.io} API,
        and one that pulls out a list of release-names from a given github
        project using Scalaj-HTTP, uPickle's JSON package, and the Github API:

      @hl.ref(wd/'integration/'src/'test/'resources/'ammonite/'integration/'basic/"HttpApi.sc")

      @p
        You can run @code{amm} on the script to see what it can do

      @hl.sh
        > amm HttpApi.sc
        Need to specify a main method to call when running HttpApi.sc

        Available main methods:

        def shorten(longUrl: String)
        def listReleases(project: String)
      @p
        And you can run the two functions via

      @hl.sh
        > amm HttpApi.sc shorten https://www.github.com
        https://git.io/vDN6Ig
      @p
        Or

      @hl.sh
        > amm HttpApi.sc listReleases lihaoyi/Ammonite
        0.7.0,Snaphot Commit Uploads,0.6.2,0.6.1,0.6.0,0.5.9,0.5.8,
        0.5.7,0.5.6,0.5.5,0.5.4,0.5.3,0.5.2,0.5.1,0.5.0,0.4.9,0.4.8,
        0.4.7,0.4.6,0.4.5,0.4.4,0.4.3,0.4.2,0.4.0

  @sect{Running Scripts}
    @p
      There are two way main ways to run Ammonite scripts:
      @sect.ref{From the REPL} and @sect.ref{From Bash}.

    @sect{From the REPL}
      @p
        You can load any script into the Ammonite REPL using the
        @hl.scala{import $file} syntax, for example here we import the above
        @hl.scala{MyScript.sc} file to access its @hl.scala{x} value:

      @hl.scala
        @@ x // doesn't work yet
        Compilation Failed
        cmd0.scala:1: not found: value x
        val res0 = x // doesn't work yet
                   ^
        @@ import $file.MyScript
        Welcome to the XYZ custom REPL!!

        @@ MyScript.x // You can refer to definitions from that module
        res1: Int = 123

        @@ import MyScript._

        @@ x // works
        res2: Int = 123

      @p
        You can also import the module, and any associated definitions you want,
        in the same import:

      @hl.scala
        @@ x // doesn't work yet
        Compilation Failed
        cmd0.scala:1: not found: value x
        val res0 = x // doesn't work yet
                   ^
        @@ import $file.MyScript, MyScript._
        Welcome to the XYZ custom REPL!!

        @@ x
        res1: Int = 123

      @p
        Note that by default, scripts imported via @code{$file} are
        @i{encapsulated}, so any imports inside that @code{MyScript} performs are
        not available outside of @code{MyScript.sc}:

      @hl.scala
        @@ import $file.MyScript, MyScript._
        Welcome to the XYZ custom REPL!!
        import $file.$
        @@ mutable.Buffer(x)
        cmd1.scala:1: not found: value mutable
        val res1 = mutable.Buffer(x)
                   ^
        Compilation Failed
      @p
        As you can see, even though @code{collection.mutable} was imported inside
        @code{MyScript.sc}, you cannot use them outside after importing it.

      @p
        If you want to make everything (both imports and definitions) available
        by default after importing, you can use an @code{$exec} import instead of
        @code{$file}:

      @hl.scala
        @@ import $exec.MyScript
        Welcome to the XYZ custom REPL!!
        import $exec.$
        @@ mutable.Buffer(x)
        res1: mutable.Buffer[Int] = ArrayBuffer(123)
      @p
        As you can see, now @code{mutable} is available, and so is @code{x} even
        though we did not directly import it.

      @p
        While @code{$file} imports are useful for defining re-usable modules with
        common functions and definitions, @code{$exec} imports are useful as
        aliases for common setup to get your REPL environment just the way you
        want it. Of course, any files you import via @hl.scala{import $file} or
        @hl.scala{import $exec} can themselves import other Scala scripts in the
        same way, and the same rules apply.

    @sect{From Bash}
      @p
        Apart from loading scripts within the @sect.ref{Ammonite-REPL}, You can
        also run scripts using the Ammonite executable from an external shell
        (e.g. bash):


      @hl.sh
        @replCurl

      @hl.scala
        bash$ ./amm path/to/script.scala
  
      @p
        All types, values and imports defined in scripts are available to
        commands entered in REPL after loading the script.
  
      @p
        You can also make an Ammonite script self-executable by using a shebang
        @hl.scala{#!}. This is an example script named @hl.scala{hello}. There
        is no need to add the @hl.scala{.scala} extension. The @hl.scala{amm}
        command needs to be in the @hl.scala{PATH}:
      @hl.sh
        #!/usr/bin/env amm
  
        println("hello world")
      @p
        make it executable and run it from an external shell (e.g. bash):
      @hl.sh
        $ chmod +x /path/to/script
        $ /path/to/script

    @sect{Execution Model}
      @p
        Ammonite's Scala Scripts run as normal Scala code, though with some
        simple source-to-source transformations applied first to turn the
        script syntax (which allows top-level expressions, @hl.scala{def}s,
        @hl.scala{val}s, etc.) into valid Scala syntax (which doesn't). What
        happens is roughly:

      @ul
        @li
          A script file is read off disk
        @li
          If the script file has been compiled/executed before, the previously
          compiled bytecode and metadata is loaded from the
          @code{~/.ammonite/cache}. If not, the script is parsed but @i{not
          yet} compiled.
        @li
          @sect.ref{Multi-stage Scripts} are split into multiple individual
          scripts, to be handled separately/sequentially.
        @li
          Any @sect.ref{Magic Imports} are resolved: any
          @sect.ref("import $ivy", "Ivy dependencies are downloaded"), or any
          @sect.ref("import $file", "imported scripts") are themselves run.
          Any imported scripts are themselves handled in the same way, as are
          any scripts @i{they} import, etc.

        @li
          If the script has already been previously compiled and cached, the
          cached bytecode that was read off of disk earlier is executed.

        @li
          Otherwise, the source code for this script is then wrapped in a
          @hl.scala{package}/@hl.scala{object} wrapper, corresponding to the
          path to the script from the current working directory. For example,
          a script at path @code{foo/bar/baz/Qux.scala} will be wrapped in:

          @hl.scala

            package foo.bar.baz
            object Qux{
              // script code
            }


        @li
          The script is then compiled and executed.

      @p
        In general, due to Scala's slow compiler, Scala Scripts rely heavily
        on caching to achieve reasonable performance. While the first run of a
        modified script has a few-seconds overhead due to the Scala compiler,
        subsequent runs of the same script should be fast-ish, with only a few
        100ms overhead for spinning up a JVM.

      @p
        Although this is much slower than other scripting languages like Bash
        (which starts up in ~4ms) or Python (~30ms), in practice it is
        acceptable for many use cases. You probably do not want to
        @code{find . | xargs amm Foo.scala} on large numbers of files, where
        the 100ms overhead will add up, but for individual scripts it should
        be fine.
      @p
        Furthermore, Ammonite makes it really easy to include that sort of
        recursive/iterative logic inside a single script: you can use
        @hl.scala{ls!} or @hl.scala{ls.rec!} from @sect.ref{Ammonite-Ops} to
        traverse the filesystem and work on multiple files all within the same
        process, which avoids duplicating the startup overhead on all the files
        you are manipulating.